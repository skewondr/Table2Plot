{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random \n",
    "from random import sample\n",
    "\n",
    "plot_type = 'pie'\n",
    "data_dir_name = 'cv_'+plot_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'plots/s_{plot_type}_annotation.pkl', 'rb') as handle:\n",
    "    raw_s_pickle = pickle.load(handle)\n",
    "\n",
    "with open(f'plots/h_{plot_type}_annotation.pkl', 'rb') as handle:\n",
    "    raw_h_pickle = pickle.load(handle)\n",
    "\n",
    "t2p = 0\n",
    "with open(f'plots/{plot_type}_annotation.pkl', 'rb') as handle:\n",
    "    raw_t2p_pickle = pickle.load(handle)\n",
    "    t2p+=len(raw_t2p_pickle)\n",
    " #table 2 plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_s_pickle[0].keys(), raw_s_pickle[0]['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import cv2\n",
    "\n",
    "#remove overlapped bbox\n",
    "#xml bbox --> yolo bbox\n",
    "\n",
    "def intersects(bbox_a, bbox_b):\n",
    "    return not (bbox_a[2] <= bbox_b[0] or bbox_a[0] >= bbox_b[2] or bbox_a[3] <= bbox_b[1] or bbox_a[1] >= bbox_b[3])\n",
    "\n",
    "def check_overlapped_text_bbox(bboxes):\n",
    "    text_bboxes = []\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        label, raw_bbox, gt_text = bbox\n",
    "        if gt_text:\n",
    "            text_bboxes.append(raw_bbox)\n",
    "    for i, text_bbox_a in enumerate(text_bboxes):\n",
    "        for j, text_bbox_b in enumerate(text_bboxes[i+1:]):\n",
    "            if intersects(text_bbox_a, text_bbox_b):\n",
    "                return True\n",
    "\n",
    "def generate_bbox(image_dir, coordinates, img_shape, margin=0):\n",
    "    #xml(xmin, ymin, xmax, ymax) -> yolo(xcenter, ycenter, width, height) \n",
    "    xmin, ymin, xmax, ymax = coordinates\n",
    "    if image_dir not in [\"human\", \"sample\"]:\n",
    "        y_max_invert = img_shape[0] - ymin\n",
    "        y_min_invert = img_shape[0] - ymax\n",
    "        ymin = y_min_invert\n",
    "        ymax = y_max_invert\n",
    "\n",
    "    width = abs(xmin - xmax)\n",
    "    height = abs(ymin - ymax)\n",
    "    x_center = (xmin + width / 2) / img_shape[1]\n",
    "    y_center = (ymin + height / 2) / img_shape[0]\n",
    "\n",
    "    width = width / img_shape[1]\n",
    "    height = height / img_shape[0]\n",
    "\n",
    "    yolo_bbox = [x_center, y_center, width, height]\n",
    "\n",
    "\n",
    "\n",
    "    overval = False\n",
    "    for i in yolo_bbox:\n",
    "        if i < 0 or i > 1: overval = True\n",
    "    \n",
    "    return yolo_bbox, overval\n",
    "\n",
    "def raw_to_data(anno_list, image_dir):\n",
    "    new_pickle = []\n",
    "    for anno_id, anno in enumerate(tqdm(anno_list, leave=True, position=0)):\n",
    "        image_name = anno['image']\n",
    "        overlapped = check_overlapped_text_bbox(anno['bboxes'])\n",
    "        if overlapped:\n",
    "            # print(f\"overlapped text bbox in {image_dir}/{image_name}\")\n",
    "            continue\n",
    "        img_data = cv2.imread(f'./plots/{image_dir}/{image_name}')\n",
    "        new_bboxes = []\n",
    "        for bbox in anno['bboxes']:\n",
    "            label, raw_bbox, gt_text = bbox\n",
    "            yolo_bbox, overval = generate_bbox(image_dir, raw_bbox, img_data.shape[:-1])\n",
    "            if overval:\n",
    "                # print(f\"bbox not in range 0~1 {image_dir}/{image_name}\")\n",
    "                continue\n",
    "            else: \n",
    "                new_bboxes.append((label, yolo_bbox, gt_text))\n",
    "        anno['bboxes'] = new_bboxes\n",
    "        new_pickle.append(anno)\n",
    "    return new_pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 132.66it/s]\n",
      "100%|██████████| 60/60 [00:00<00:00, 294.34it/s]\n",
      "100%|██████████| 2351/2351 [00:41<00:00, 56.68it/s]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "s_pickle = raw_to_data(raw_s_pickle, \"sample\")\n",
    "h_pickle = raw_to_data(raw_h_pickle, \"human\")\n",
    "t2p_pickle = raw_to_data(raw_t2p_pickle, plot_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-----before  pickle-----#\n",
      "s: 2\n",
      "h: 60\n",
      "t2p: 2351\n",
      "#-----after pickle-----#\n",
      "s pie: 2\n",
      "h: 43\n",
      "t2p: 1674\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('#-----before  pickle-----#')\n",
    "print(f\"s:\",len(raw_s_pickle))\n",
    "print(f\"h:\", len(raw_h_pickle))\n",
    "print(f\"t2p:\",t2p)\n",
    "print('#-----after pickle-----#')\n",
    "print(f\"s {plot_type}:\",len(s_pickle))\n",
    "print(f\"h:\", len(h_pickle))\n",
    "print(f\"t2p:\",len(t2p_pickle))\n",
    "# #-----before  pickle-----#\n",
    "# s: 3\n",
    "# h: 105\n",
    "# t2p: 1665\n",
    "# #-----after pickle-----#\n",
    "# s: 3\n",
    "# h: 95\n",
    "# t2p: 1565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1511\n",
      "valid: 80\n",
      "a test: 2\n",
      "b test: 43\n",
      "c test: 83\n",
      "total: 1719\n"
     ]
    }
   ],
   "source": [
    "a_file_names = [ann['image'] for ann in s_pickle]\n",
    "b_file_names = [ann['image'] for ann in h_pickle]\n",
    "c_file_names = [ann['image'] for ann in t2p_pickle]\n",
    "\n",
    "a_test_num = len(a_file_names)\n",
    "b_test_num = 43\n",
    "c_test_num = int(len(c_file_names)*0.05)\n",
    "\n",
    "np.random.seed(123) # random한 것은 반드시!!!! seed를 위에 붙여줘야 고정됨.건드리지 말것.\n",
    "random.seed(123) # random한 것은 반드시!!!! seed를 위에 붙여줘야 고정됨.건드리지 말것.\n",
    "np.random.shuffle(a_file_names)\n",
    "np.random.shuffle(b_file_names)\n",
    "np.random.shuffle(c_file_names)\n",
    "\n",
    "np.random.seed(123) # random한 것은 반드시!!!! seed를 위에 붙여줘야 고정됨.건드리지 말것.\n",
    "random.seed(123) # random한 것은 반드시!!!! seed를 위에 붙여줘야 고정됨.건드리지 말것.\n",
    "#sample\n",
    "a_test_names_set = set(list(sample(a_file_names, a_test_num)))\n",
    "#human\n",
    "b_test_names_set = set(list(sample(b_file_names, b_test_num)))\n",
    "#automatic\n",
    "c_test_names_set = set(list(sample(c_file_names, c_test_num)))\n",
    "\n",
    "trnval_file_names = []\n",
    "for i in a_file_names:\n",
    "    if i in a_test_names_set: continue\n",
    "    else:\n",
    "        trnval_file_names.append(i)\n",
    "for i in b_file_names:\n",
    "    if i in b_test_names_set: continue\n",
    "    else:\n",
    "        trnval_file_names.append(i)\n",
    "for i in c_file_names:\n",
    "    if i in c_test_names_set: continue\n",
    "    else: \n",
    "        trnval_file_names.append(i)\n",
    "\n",
    "np.random.seed(123) # random한 것은 반드시!!!! seed를 위에 붙여줘야 고정됨. 건드리지 말것.\n",
    "random.seed(123) # random한 것은 반드시!!!! seed를 위에 붙여줘야 고정됨. 건드리지 말것.\n",
    "trn_names_set = sample(trnval_file_names, int(len(trnval_file_names)*0.95))\n",
    "train_num = len(trn_names_set)\n",
    "val_names_set = [i for i in trnval_file_names if i not in trn_names_set]\n",
    "valid_num = len(val_names_set)\n",
    "\n",
    "print(\"train:\", len(trn_names_set))\n",
    "print(\"valid:\", len(val_names_set))\n",
    "print(\"a test:\", len(a_test_names_set))\n",
    "print(\"b test:\", len(b_test_names_set))\n",
    "print(\"c test:\", len(c_test_names_set))\n",
    "print(\"total:\", len(trn_names_set)+len(val_names_set)+len(a_test_names_set)+len(b_test_names_set)+len(c_test_names_set) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n필요한 코드 \\n-labels 폴더 내 train / valid / testA / testB / test C 폴더 내 {이미지 이름}.txt 파일 생성\\n-images 폴더 내 train / valid / testA / testB / test C 복사된 이미지 파일 \\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "#GUIDE LINE\n",
    "###################################\n",
    "\"\"\"\n",
    "필요한 코드 \n",
    "-labels 폴더 내 train / valid / testA / testB / test C 폴더 내 {이미지 이름}.txt 파일 생성\n",
    "-images 폴더 내 train / valid / testA / testB / test C 복사된 이미지 파일 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label ={\n",
    "  0: \"title\",\n",
    "  1: \"t_legend\",\n",
    "  2: \"x_label\",\n",
    "  3: \"y_label\",\n",
    "  4: \"x_tick\",\n",
    "  5: \"y_tick\",\n",
    "  6: \"val\",\n",
    "  7: \"pietick_0\",\n",
    "  8: \"pietick_1\",\n",
    "  9: \"pietick_2\",\n",
    "  10: \"pietick_3\",\n",
    "  11: \"pietick_4\",\n",
    "  12: \"pietick_5\",\n",
    "  13: \"pietick_6\",\n",
    "  14: \"pietick_7\",\n",
    "  15: \"pietick_8\",\n",
    "  16: \"pietick_9\",\n",
    "  17: \"pietick_10\",\n",
    "  18: \"pietick_11\",\n",
    "  19: \"pietick_12\",\n",
    "  20: \"pietick_13\",\n",
    "  21: \"pietick_14\",\n",
    "  22: \"pieval_0\",\n",
    "  23: \"pieval_1\",\n",
    "  24: \"pieval_2\",\n",
    "  25: \"pieval_3\",\n",
    "  26: \"pieval_4\",\n",
    "  27: \"pieval_5\",\n",
    "  28: \"pieval_6\",\n",
    "  29: \"pieval_7\",\n",
    "  30: \"pieval_8\",\n",
    "  31: \"pieval_9\",\n",
    "  32: \"pieval_10\",\n",
    "  33: \"pieval_11\",\n",
    "  34: \"pieval_12\",\n",
    "  35: \"pieval_13\",\n",
    "  36: \"pieval_14\",\n",
    "  37: \"pieratio_0\",\n",
    "  38: \"pieratio_1\",\n",
    "  39: \"pieratio_2\",\n",
    "  40: \"pieratio_3\",\n",
    "  41: \"pieratio_4\",\n",
    "  42: \"pieratio_5\",\n",
    "  43: \"pieratio_6\",\n",
    "  44: \"pieratio_7\",\n",
    "  45: \"pieratio_8\",\n",
    "  46: \"pieratio_9\",\n",
    "  47: \"pieratio_10\",\n",
    "  48: \"pieratio_11\",\n",
    "  49: \"pieratio_12\",\n",
    "  50: \"pieratio_13\",\n",
    "  51: \"pieratio_14\",\n",
    "  52: \"v_legend\",\n",
    "  53: \"line_0\",\n",
    "  54: \"line_1\",\n",
    "  55: \"line_2\",\n",
    "  56: \"line_3\",\n",
    "  57: \"line_4\",\n",
    "  58: \"line_5\",\n",
    "  59: \"line_6\",\n",
    "  60: \"line_7\",\n",
    "  61: \"line_8\",\n",
    "  62: \"line_9\",\n",
    "  63: \"bar\",\n",
    "  64: \"wedge_0\",\n",
    "  65: \"wedge_1\",\n",
    "  66: \"wedge_2\",\n",
    "  67: \"wedge_3\",\n",
    "  68: \"wedge_4\",\n",
    "  69: \"wedge_5\",\n",
    "  70: \"wedge_6\",\n",
    "  71: \"wedge_7\",\n",
    "  72: \"wedge_8\",\n",
    "  73: \"wedge_9\",\n",
    "  74: \"wedge_10\",\n",
    "  75: \"wedge_11\",\n",
    "  76: \"wedge_12\",\n",
    "  77: \"wedge_13\",\n",
    "  78: \"wedge_14\",\n",
    "}\n",
    "\n",
    "idx2label_new ={\n",
    "  0: \"title\",\n",
    "  1: \"t_legend\",\n",
    "  2: \"x_label\",\n",
    "  3: \"y_label\",\n",
    "  4: \"x_tick\",\n",
    "  5: \"y_tick\",\n",
    "  6: \"val\",\n",
    "  7: \"v_legend\",\n",
    "  8: \"line\",\n",
    "  9: \"bar\",\n",
    "  10: \"wedge\",\n",
    "}\n",
    "\n",
    "label2idx = dict()\n",
    "for k, v in idx2label_new.items():\n",
    "  label2idx[v] = k\n",
    "\n",
    "def trans_cat(cat_text):\n",
    "  if cat_text.startswith('pie'): cat_text = 'val'\n",
    "  elif cat_text.startswith('wedge'): cat_text = 'wedge'\n",
    "  elif cat_text.startswith('line'): cat_text = 'line'\n",
    "  return label2idx[cat_text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "def mkdirs(newdir,mode=777):\n",
    "    try:\n",
    "        os.makedirs(newdir, mode)\n",
    "    except OSError as err:\n",
    "        return err\n",
    "\n",
    "def set_img_label(anno_list, anno_name_list, split_list, split_name, dataset_name): \n",
    "    # [s_pickle], [\"sample\"], a_test_names_set, \"testA\", \"abc_bar\"\n",
    "    image_path = f'{dataset_name}/images/{split_name}'\n",
    "    label_path = f'{dataset_name}/labels/{split_name}'\n",
    "    mkdirs(image_path)\n",
    "    mkdirs(label_path)\n",
    "\n",
    "    if split_name in [\"train\", \"valid\"] and dataset_name.startswith(\"c_\"):\n",
    "        anno_list.pop(0)\n",
    "        anno_name_list.pop(0)\n",
    "    cnt = 0 \n",
    "    for annos, names in zip(tqdm(anno_list, ncols=100, leave=True, position=0), anno_name_list):\n",
    "        image_source = f'plots/{names}'\n",
    "        for anno_id, anno in enumerate(annos):\n",
    "            image_name = anno['image']\n",
    "            if image_name in split_list:\n",
    "                cnt += 1\n",
    "                os.system('chmod 777 -R *')\n",
    "                copyfile(os.path.join(image_source, image_name) , os.path.join(image_path, image_name))\n",
    "                f = open(os.path.join(label_path, image_name[:-4]+\".txt\"), 'w')\n",
    "                for bbox in anno['bboxes']:\n",
    "                    label, yolo_bbox, gt_text = bbox\n",
    "                    cat = trans_cat(label)\n",
    "                    if cat in np.arange(0, 7) and 't' not in dataset_name: continue#text이면서 클래스 내에 포함하면 안되는 경우: 제외\n",
    "                    if cat in np.arange(7, 11) and 'v' not in dataset_name: continue#visual이면서 클래스 내에 포함하면 안되는 경우: 제외\n",
    "                    xcenter, ycenter, width, height = yolo_bbox\n",
    "                    row = f\"{cat} {xcenter} {ycenter} {width} {height}\\n\"\n",
    "                    f.write(row)\n",
    "    print(f\"total ={cnt}\" )\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [02:41<00:00, 80.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:09<00:00,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total =83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# dataset= [trn_names_set, val_names_set, a_test_names_set, b_test_names_set, c_test_names_set ]\n",
    "# pickle = [s_pickle, h_pickle, t2p_pickle]\n",
    "\n",
    "# data_dir_name = 'c_'+plot_type\n",
    "\n",
    "#< [s_pickle], \"sample\", a_test_names_set, \"testA\", data_dir_name >\n",
    "set_img_label([h_pickle, t2p_pickle], [\"human\", plot_type], trn_names_set, \"train\", data_dir_name) \n",
    "set_img_label([h_pickle, t2p_pickle], [\"human\", plot_type], val_names_set, \"valid\", data_dir_name)\n",
    "set_img_label([s_pickle], [\"sample\"], a_test_names_set, \"testA\", data_dir_name)\n",
    "set_img_label([h_pickle], [\"human\"], b_test_names_set, \"testB\", data_dir_name)\n",
    "set_img_label( [t2p_pickle], [plot_type], c_test_names_set, \"testC\", data_dir_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('detector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03b39547a910955c30194aa126297ed2d164571210c5e5d115aca1e620d93d63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
